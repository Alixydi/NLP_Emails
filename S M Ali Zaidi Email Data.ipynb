{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S M Ali Zaidi\n",
    "# DS 4 Violet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "el1V1B6DRaOE",
    "outputId": "dc7dc5ce-95d8-41b8-be3e-e97bf7514479"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Sohaib\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Sohaib\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Sohaib\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "tZLTcZvZDPIF"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Sohaib\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   S. No.                                       Message_body     Label\n",
      "0       1                         Rofl. Its true to its name  Non-Spam\n",
      "1       2  The guy did some bitching but I acted like i'd...  Non-Spam\n",
      "2       3  Pity, * was in mood for that. So...any other s...  Non-Spam\n",
      "3       4               Will ü b going to esplanade fr home?  Non-Spam\n",
      "4       5  This is the 2nd time we have tried 2 contact u...      Spam\n",
      "   S. No.                                       Message_body Label\n",
      "0       1  UpgrdCentre Orange customer, you may now claim...  Spam\n",
      "1       2  Loan for any purpose £500 - £75,000. Homeowner...  Spam\n",
      "2       3  Congrats! Nokia 3650 video camera phone is you...  Spam\n",
      "3       4  URGENT! Your Mobile number has been awarded wi...  Spam\n",
      "4       5  Someone has contacted our dating service and e...  Spam\n"
     ]
    }
   ],
   "source": [
    "# Load the training data\n",
    "train_data = pd.read_csv('/Users/Sohaib/Documents/ATOM CAMP/Natural Language Processing/Assignment 1/Email/SMS_train.csv', encoding='latin1')\n",
    "\n",
    "# Load the test data\n",
    "test_data = pd.read_csv('/Users/Sohaib/Documents/ATOM CAMP/Natural Language Processing/Assignment 1/Email/SMS_test.csv', encoding='latin1')\n",
    "\n",
    "print(train_data.head())\n",
    "\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Removing punctuations like., ! $( ) * % @\n",
    "2. Removing URLs\n",
    "3. Removing Stop words\n",
    "4. Lower casing\n",
    "5. Tokenization\n",
    "6. Stemming\n",
    "7. Lemmatization\n",
    "8. Sentence Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        Message_body  \\\n",
      "0                         Rofl. Its true to its name   \n",
      "1  The guy did some bitching but I acted like i'd...   \n",
      "2  Pity, * was in mood for that. So...any other s...   \n",
      "3               Will ü b going to esplanade fr home?   \n",
      "4  This is the 2nd time we have tried 2 contact u...   \n",
      "\n",
      "                                      text_processed  \n",
      "0                                   [rofl true name]  \n",
      "1  [guy bitching acted like id interested buying ...  \n",
      "2                       [pity mood soany suggestion]  \n",
      "3                        [b going esplanade fr home]  \n",
      "4  [2nd time tried 2 contact u u 750 pound prize ...  \n",
      "                                        Message_body  \\\n",
      "0  UpgrdCentre Orange customer, you may now claim...   \n",
      "1  Loan for any purpose £500 - £75,000. Homeowner...   \n",
      "2  Congrats! Nokia 3650 video camera phone is you...   \n",
      "3  URGENT! Your Mobile number has been awarded wi...   \n",
      "4  Someone has contacted our dating service and e...   \n",
      "\n",
      "                                      text_processed  \n",
      "0  [upgrdcentre orange customer may claim free ca...  \n",
      "1  [loan purpose 500 75000 homeowner tenant welco...  \n",
      "2  [congrats nokia 3650 video camera phone call 0...  \n",
      "3  [urgent mobile number awarded 2000 prize guara...  \n",
      "4  [someone contacted dating service entered phon...  \n"
     ]
    }
   ],
   "source": [
    "# Initializing stemmer and lemmatizer\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Loading English stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to remove special characters and punctuations\n",
    "def remove_special_characters(text):\n",
    "    pattern = r'[^a-zA-Z0-9\\s]'  # Keep only alphanumeric characters and spaces\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "# Function to remove URLs\n",
    "def remove_urls(text):\n",
    "    url_pattern = r'https?://\\S+|www\\.\\S+'\n",
    "    text = re.sub(url_pattern, '', text)\n",
    "    return text\n",
    "\n",
    "# Function to remove stop words\n",
    "def remove_stop_words(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "# Function for lowercasing\n",
    "def lowercase_text(text):\n",
    "    return text.lower()\n",
    "\n",
    "# Function for tokenization\n",
    "def tokenize_text(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "# Function for stemming\n",
    "def stem_text(tokens):\n",
    "    stemmed_tokens = [stemmer.stem(word) for word in tokens]\n",
    "    return ' '.join(stemmed_tokens)\n",
    "\n",
    "# Function for lemmatization\n",
    "def lemmatize_text(tokens):\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "# Function for sentence segmentation\n",
    "def segment_sentences(text):\n",
    "    return sent_tokenize(text)\n",
    "\n",
    "# Combined preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = lowercase_text(text)\n",
    "    text = remove_urls(text)\n",
    "    text = remove_special_characters(text)\n",
    "    text = remove_stop_words(text)\n",
    "    tokens = tokenize_text(text)\n",
    "    stemmed_text = stem_text(tokens)  # stemming\n",
    "    lemmatized_text = lemmatize_text(tokens)  # lemmatization\n",
    "    sentences = segment_sentences(lemmatized_text)  # Sentence segmentation on lemmatized text\n",
    "    return sentences  # Returns a list of sentences\n",
    "\n",
    "# Applying preprocessing to the DataFrame\n",
    "train_data['text_processed'] = train_data['Message_body'].apply(preprocess_text)\n",
    "test_data['text_processed'] = test_data['Message_body'].apply(preprocess_text)\n",
    "\n",
    "# Displaying the first few rows to verify\n",
    "print(train_data[['Message_body', 'text_processed']].head())\n",
    "print(test_data[['Message_body', 'text_processed']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
